{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab5f4560",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-30 12:41:32.756836: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1748601692.787644    2487 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1748601692.791346    2487 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-05-30 12:41:32.808146: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "import re\n",
    "from collections import defaultdict, Counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c06571",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples: 1301608\n"
     ]
    }
   ],
   "source": [
    "sent_data_path = 'data/zh_sent_dataset.tsv'\n",
    "t9_data_path = 'data/zh_T9_dataset.tsv'\n",
    "\n",
    "sentences = pd.read_csv(sent_data_path, sep=\"\\t\", header=None, names=[\"sentence\"])\n",
    "codes = pd.read_csv(t9_data_path, sep=\"\\t\", header=None, names=[\"code\", \"char\"])\n",
    "codes = codes.drop_duplicates(subset=[\"code\", \"char\"]).reset_index(drop=True)\n",
    "\n",
    "# Build Nine-Key Code Mappings\n",
    "code2chars = defaultdict(list)\n",
    "char2code = {}\n",
    "\n",
    "for _, row in codes.iterrows():\n",
    "    code2chars[row.code].append(row.char)\n",
    "    char2code[row.char] = row.code\n",
    "\n",
    "# Build Training Samples\n",
    "# For each character in sentence, use previous text as context and current code as input\n",
    "\n",
    "samples = []\n",
    "\n",
    "window_size = 20  # Limit context length (in characters)\n",
    "\n",
    "for sentence in sentences[\"sentence\"]:\n",
    "    sentence = re.sub(r\"[^\\u4e00-\\u9fa5]\", \"\", sentence)  # Remove non-Chinese characters\n",
    "    for i in range(len(sentence)):\n",
    "        char = sentence[i]\n",
    "        code = char2code.get(char)\n",
    "        if code is None:\n",
    "            continue\n",
    "        context = sentence[max(0, i - window_size):i]\n",
    "        samples.append((context, code, char))\n",
    "\n",
    "print(f\"Total samples: {len(samples)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0bd0a289",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Build Vocabulary & Vectorization\n",
    "all_chars = sorted(set(char2code.keys()))\n",
    "char2idx = {c: i + 1 for i, c in enumerate(all_chars)}  # 0 用作 padding\n",
    "idx2char = {i: c for c, i in char2idx.items()}\n",
    "\n",
    "code_set = sorted(code2chars.keys())\n",
    "code2idx = {c: i + 1 for i, c in enumerate(code_set)}  # 0 为 padding\n",
    "\n",
    "max_context_len = window_size\n",
    "\n",
    "def encode_context(text):\n",
    "    return [char2idx.get(c, 0) for c in text][-max_context_len:]\n",
    "\n",
    "def encode_code(code):\n",
    "    return code2idx.get(code, 0)\n",
    "\n",
    "X_context = []\n",
    "X_code = []\n",
    "Y_char = []\n",
    "\n",
    "for ctx, code, char in samples:\n",
    "    X_context.append(encode_context(ctx))\n",
    "    X_code.append(encode_code(code))\n",
    "    Y_char.append(char2idx[char])\n",
    "\n",
    "# Padding\n",
    "X_context = keras.preprocessing.sequence.pad_sequences(X_context, maxlen=max_context_len, padding='pre')\n",
    "X_code = np.array(X_code)\n",
    "Y_char = np.array(Y_char)\n",
    "\n",
    "X_train_ctx, X_temp_ctx, X_train_code, X_temp_code, y_train, y_temp = train_test_split(\n",
    "    X_context, X_code, Y_char, test_size=0.2, random_state=42)\n",
    "\n",
    "X_val_ctx, X_test_ctx, X_val_code, X_test_code, y_val, y_test = train_test_split(\n",
    "    X_temp_ctx, X_temp_code, y_temp, test_size=0.5, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26d883fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1748601782.562044    2487 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5582 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ context_input       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,795,200</span> │ context_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ not_equal           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NotEqual</span>)          │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ code_input          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)            │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ masking (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Masking</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ any (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Any</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ not_equal[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_1         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │    <span style=\"color: #00af00; text-decoration-color: #00af00\">774,080</span> │ code_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ bidirectional       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">66,048</span> │ masking[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │                   │            │ any[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ embedding_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ bidirectional[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ flatten[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">20,608</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">43675</span>)     │  <span style=\"color: #00af00; text-decoration-color: #00af00\">5,634,075</span> │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ context_input       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │  \u001b[38;5;34m2,795,200\u001b[0m │ context_input[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ not_equal           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mNotEqual\u001b[0m)          │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ code_input          │ (\u001b[38;5;45mNone\u001b[0m)            │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ masking (\u001b[38;5;33mMasking\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ any (\u001b[38;5;33mAny\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ not_equal[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_1         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │    \u001b[38;5;34m774,080\u001b[0m │ code_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ bidirectional       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │     \u001b[38;5;34m66,048\u001b[0m │ masking[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n",
       "│ (\u001b[38;5;33mBidirectional\u001b[0m)     │                   │            │ any[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ embedding_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m160\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ bidirectional[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ flatten[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │     \u001b[38;5;34m20,608\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m43675\u001b[0m)     │  \u001b[38;5;34m5,634,075\u001b[0m │ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,290,011</span> (35.44 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m9,290,011\u001b[0m (35.44 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,290,011</span> (35.44 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m9,290,011\u001b[0m (35.44 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vocab_size = len(char2idx) + 1\n",
    "code_vocab_size = len(code2idx) + 1\n",
    "embedding_dim = 64\n",
    "\n",
    "ctx_input = keras.Input(shape=(max_context_len,), name=\"context_input\")\n",
    "ctx_emb = layers.Embedding(input_dim=vocab_size, output_dim=embedding_dim, mask_zero=False)(ctx_input)\n",
    "ctx_emb = layers.Masking(mask_value=0.0)(ctx_emb)\n",
    "ctx_encoded = layers.Bidirectional(\n",
    "layers.LSTM(64, recurrent_activation=\"sigmoid\")\n",
    ")(ctx_emb)\n",
    "\n",
    "code_input = keras.Input(shape=(), dtype=tf.int32, name=\"code_input\")\n",
    "code_emb = layers.Embedding(input_dim=code_vocab_size, output_dim=32)(code_input)\n",
    "code_encoded = layers.Flatten()(code_emb)\n",
    "\n",
    "merged = layers.concatenate([ctx_encoded, code_encoded])\n",
    "hidden = layers.Dense(128, activation=\"relu\")(merged)\n",
    "output = layers.Dense(vocab_size, activation=\"softmax\")(hidden)\n",
    "\n",
    "model = keras.Model(inputs=[ctx_input, code_input], outputs=output)\n",
    "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf191add",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-30 12:43:10.705438: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 83302880 exceeds 10% of free system memory.\n",
      "2025-05-30 12:43:11.633056: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 22361600 exceeds 10% of free system memory.\n",
      "I0000 00:00:1748601793.009223    2931 cuda_dnn.cc:529] Loaded cuDNN version 90300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4068/4068\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 35ms/step - accuracy: 0.3309 - loss: 3.6645 - val_accuracy: 0.5403 - val_loss: 1.6312\n",
      "Epoch 2/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-30 12:45:35.212821: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 22361600 exceeds 10% of free system memory.\n",
      "2025-05-30 12:45:35.278099: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 22361600 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4068/4068\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 35ms/step - accuracy: 0.5613 - loss: 1.5434 - val_accuracy: 0.5973 - val_loss: 1.4175\n",
      "Epoch 3/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-30 12:48:55.704249: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 22361600 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4068/4068\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 33ms/step - accuracy: 0.6111 - loss: 1.3468 - val_accuracy: 0.6247 - val_loss: 1.3209\n",
      "Epoch 4/15\n",
      "\u001b[1m4068/4068\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m151s\u001b[0m 35ms/step - accuracy: 0.6393 - loss: 1.2332 - val_accuracy: 0.6411 - val_loss: 1.2708\n",
      "Epoch 5/15\n",
      "\u001b[1m4068/4068\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 35ms/step - accuracy: 0.6566 - loss: 1.1625 - val_accuracy: 0.6507 - val_loss: 1.2422\n",
      "Epoch 6/15\n",
      "\u001b[1m4068/4068\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 33ms/step - accuracy: 0.6704 - loss: 1.1091 - val_accuracy: 0.6602 - val_loss: 1.2245\n",
      "Epoch 7/15\n",
      "\u001b[1m4068/4068\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 33ms/step - accuracy: 0.6830 - loss: 1.0632 - val_accuracy: 0.6654 - val_loss: 1.2046\n",
      "Epoch 8/15\n",
      "\u001b[1m4068/4068\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 35ms/step - accuracy: 0.6929 - loss: 1.0251 - val_accuracy: 0.6704 - val_loss: 1.1973\n",
      "Epoch 9/15\n",
      "\u001b[1m4068/4068\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 33ms/step - accuracy: 0.7014 - loss: 0.9918 - val_accuracy: 0.6742 - val_loss: 1.1929\n",
      "Epoch 10/15\n",
      "\u001b[1m4068/4068\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 33ms/step - accuracy: 0.7079 - loss: 0.9643 - val_accuracy: 0.6772 - val_loss: 1.1936\n",
      "Epoch 11/15\n",
      "\u001b[1m4068/4068\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 33ms/step - accuracy: 0.7158 - loss: 0.9357 - val_accuracy: 0.6793 - val_loss: 1.1935\n",
      "Epoch 12/15\n",
      "\u001b[1m4068/4068\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 35ms/step - accuracy: 0.7202 - loss: 0.9150 - val_accuracy: 0.6802 - val_loss: 1.1956\n"
     ]
    }
   ],
   "source": [
    "callbacks = [\n",
    "    keras.callbacks.EarlyStopping(patience=3, restore_best_weights=True)\n",
    "]\n",
    "\n",
    "history = model.fit(\n",
    "    {\"context_input\": X_train_ctx, \"code_input\": X_train_code},\n",
    "    y_train,\n",
    "    validation_data=(\n",
    "        {\"context_input\": X_val_ctx, \"code_input\": X_val_code},\n",
    "        y_val\n",
    "    ),\n",
    "    epochs=15,\n",
    "    batch_size=256,\n",
    "    callbacks=callbacks\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5bc9e435",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4068/4068\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 11ms/step - accuracy: 0.6744 - loss: 1.1950\n",
      "Test accuracy: 0.6739\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(\n",
    "    {\"context_input\": X_test_ctx, \"code_input\": X_test_code},\n",
    "    y_test\n",
    ")\n",
    "print(f\"Test accuracy: {test_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ff979ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_next(code=None, context=\"\", topk=5):\n",
    "    ctx_enc = encode_context(context)\n",
    "    code_enc = encode_code(code) if code else 0\n",
    "    ctx_pad = keras.preprocessing.sequence.pad_sequences([ctx_enc], maxlen=max_context_len)\n",
    "    pred = model.predict({\"context_input\": ctx_pad, \"code_input\": np.array([code_enc])}, verbose=0)[0]\n",
    "    if code:\n",
    "        possible_chars = code2chars[code]\n",
    "        possible_ids = [char2idx[c] for c in possible_chars if c in char2idx]\n",
    "        filtered = [(i, pred[i]) for i in possible_ids]\n",
    "    else:\n",
    "        filtered = list(enumerate(pred))\n",
    "\n",
    "    filtered = sorted(filtered, key=lambda x: x[1], reverse=True)\n",
    "    return [(idx2char[i], score) for i, score in filtered[:topk] if i in idx2char]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1057bd49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input code=7426, context='我想知道'\n",
      "[('少', 0.24244513), ('少', 0.24244513), ('少', 0.24244513), ('少', 0.24244513), ('少', 0.24244513)]\n",
      "Input code='', context='价格'\n",
      "[('有', 0.046795007), ('是', 0.045057654), ('每', 0.04019928), ('内', 0.039380517), ('价', 0.038499665)]\n",
      "Input code='2878', context=''\n",
      "[('粗俗', 1.0067982e-05), ('不如', 9.943495e-06), ('不如', 9.943495e-06), ('不如', 9.943495e-06), ('不如', 9.943495e-06)]\n"
     ]
    }
   ],
   "source": [
    "print(\"Input code=7426, context='我想知道'\")\n",
    "print(predict_next(code='7426', context='我想知道'))\n",
    "\n",
    "print(\"Input code='', context='价格'\")\n",
    "print(predict_next(code='', context='价格'))\n",
    "\n",
    "print(\"Input code='2878', context=''\")\n",
    "print(predict_next(code='2878', context=''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "659c1870",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpm_dg0772/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpm_dg0772/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at '/tmp/tmpm_dg0772'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): List[TensorSpec(shape=(None, 20), dtype=tf.float32, name='context_input'), TensorSpec(shape=(None,), dtype=tf.int32, name='code_input')]\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 43675), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  140087889398288: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140087889400016: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140087889398672: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140087889401168: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140087889401744: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140087889400784: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140087889402320: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140087889402896: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140087889403088: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140087889403664: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140087889400592: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140087889404624: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1748603886.189156    2487 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
      "W0000 00:00:1748603886.189186    2487 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n",
      "2025-05-30 13:18:06.189343: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmpm_dg0772\n",
      "2025-05-30 13:18:06.190556: I tensorflow/cc/saved_model/reader.cc:52] Reading meta graph with tags { serve }\n",
      "2025-05-30 13:18:06.190566: I tensorflow/cc/saved_model/reader.cc:147] Reading SavedModel debug info (if present) from: /tmp/tmpm_dg0772\n",
      "2025-05-30 13:18:06.209078: I tensorflow/cc/saved_model/loader.cc:236] Restoring SavedModel bundle.\n",
      "2025-05-30 13:18:06.297441: I tensorflow/cc/saved_model/loader.cc:220] Running initialization op on SavedModel bundle at path: /tmp/tmpm_dg0772\n",
      "2025-05-30 13:18:06.328585: I tensorflow/cc/saved_model/loader.cc:466] SavedModel load for tags { serve }; Status: success: OK. Took 139244 microseconds.\n"
     ]
    }
   ],
   "source": [
    "# Rebuild the model on CPU to avoid CudnnRNN ops\n",
    "with tf.device('/CPU:0'):\n",
    "    ctx_input = keras.Input(shape=(max_context_len,), name=\"context_input\")\n",
    "    ctx_emb = layers.Embedding(input_dim=vocab_size, output_dim=embedding_dim, mask_zero=False)(ctx_input)\n",
    "    ctx_emb = layers.Masking(mask_value=0.0)(ctx_emb)\n",
    "    ctx_encoded = layers.Bidirectional(\n",
    "        layers.LSTM(64, recurrent_activation=\"sigmoid\", unroll=True)\n",
    "    )(ctx_emb)\n",
    "\n",
    "    code_input = keras.Input(shape=(), dtype=tf.int32, name=\"code_input\")\n",
    "    code_emb = layers.Embedding(input_dim=code_vocab_size, output_dim=32)(code_input)\n",
    "    code_encoded = layers.Flatten()(code_emb)\n",
    "\n",
    "    merged = layers.concatenate([ctx_encoded, code_encoded])\n",
    "    hidden = layers.Dense(128, activation=\"relu\")(merged)\n",
    "    output = layers.Dense(vocab_size, activation=\"softmax\")(hidden)\n",
    "\n",
    "    cpu_model = keras.Model(inputs=[ctx_input, code_input], outputs=output)\n",
    "    cpu_model.set_weights(model.get_weights())\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(cpu_model)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "with open(\"model/T9_predictor.tflite\", \"wb\") as f:\n",
    "    f.write(tflite_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
